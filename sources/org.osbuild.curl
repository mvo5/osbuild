#!/usr/bin/python3
"""
Source for downloading files from URLs.

The files are indexed by their content hash. Can download files
that require secrets. The only secret provider currently supported
is `org.osbuild.rhsm` for downloading Red Hat content that requires
a subscriptions.

Internally use curl to download the files; the files are cached in
an internal cache. Multiple parallel connections are used to speed
up the download.
"""

import concurrent.futures
import os
import pathlib
import re
import subprocess
import sys
import tempfile
import urllib.parse
from typing import Dict, List

from osbuild import sources
from osbuild.util.checksum import verify_file
from osbuild.util.rhsm import Subscriptions

SCHEMA = """
"additionalProperties": false,
"definitions": {
  "item": {
    "description": "The files to fetch indexed their content checksum",
    "type": "object",
    "additionalProperties": false,
    "patternProperties": {
      "(md5|sha1|sha256|sha384|sha512):[0-9a-f]{32,128}": {
        "oneOf": [
          {
            "type": "string",
            "description": "URL to download the file from."
          },
          {
            "type": "object",
            "additionalProperties": false,
            "required": [
              "url"
            ],
            "properties": {
              "url": {
                "type": "string",
                "description": "URL to download the file from."
              },
              "insecure": {
                "type": "boolean",
                "description": "Skip the verification step for secure connections and proceed without checking",
                "default": false
              },
              "secrets": {
                "type": "object",
                "additionalProperties": false,
                "required": [
                  "name"
                ],
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Name of the secrets provider."
                  }
                }
              }
            }
          }
        ]
      }
    }
  }
},
"properties": {
  "items": {"$ref": "#/definitions/item"},
  "urls": {"$ref": "#/definitions/item"}
},
"oneOf": [{
  "required": ["items"]
}, {
  "required": ["urls"]
}]
"""


def _curl_has_parallel_downloads():
    output = subprocess.check_output(["curl", "--version"], universal_newlines=True)
    m = re.match(r'^curl (\d+\.\d+\.\d+)', output.split("\n")[0])
    if not m:
        # issue warning here?
        return False
    major, minor, micro = m.group(1).split(".")
    if int(major) > 7:
        return True
    if int(major) == 7 and int(minor) >= 68:
        return True
    return False


def _gen_curl_download_config(items: Dict, config_path: pathlib.Path):
    with config_path.open("w", encoding="utf8") as fp:
        for checksum, desc in items.items():
            url = desc.get("url")
            fp.write(f'url = "{url}"\n')
            fp.write(f'output = "{checksum}"\n')
            secrets = desc.get("secrets")
            if secrets:
                ssl_ca_cert = secrets.get('ssl_ca_cert')
                if ssl_ca_cert:
                    fp.write(f'cacert = "{ssl_ca_cert}"\n')
                ssl_client_cert = secrets.get('ssl_client_cert')
                if ssl_client_cert:
                    fp.write(f'cert = "{ssl_client_cert}"\n')
                ssl_client_key = secrets.get('ssl_client_key')
                if ssl_client_key:
                    fp.write(f'key = "{ssl_client_key}"\n')

            insecure = desc.get("insecure")
            if insecure:
                fp.write(f'insecure\n')
            else:
                fp.write(f'no-insecure\n')
            fp.write("\n")


class CurlSource(sources.SourceService):

    content_type = "org.osbuild.files"

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.subscriptions = None

    def transform(self, desc):
        url = desc
        if not isinstance(url, dict):
            url = {"url": url}

        # check if url needs rhsm secrets
        if url.get("secrets", {}).get("name") == "org.osbuild.rhsm":
            # rhsm secrets only need to be retrieved once and can then be reused
            if self.subscriptions is None:
                self.subscriptions = Subscriptions.from_host_system()
            url["secrets"] = self.subscriptions.get_secrets(url.get("url"))

        return url

    def fetch_one(self):
        raise Exception("use fetch_all()")


    def fetch_all(self, items: Dict):
        # some mirrors are sometimes broken. retry manually, because we could be
        # redirected to a different, working, one on retry.
        for _ in range(10):
            # discards items already in cache
            filtered = {chksum: desc for chksum, desc in items.items()
                        if not self.exists(chksum, desc)}
            # amend items with security/subscription information
            transformed = {chksum: self.transform(desc)
                           for chksum, desc in filtered.items()}
            if len(transformed) == 0:
                break
            return_code = self.fetch_all_no_retry(transformed)
        else:
            raise RuntimeError(f"curl: error downloading {transformed}: error code {return_code}")
    
    def fetch_all_no_retry(self, items: Dict):
        # Download to a temporary sub cache until we have verified the checksum. Use a
        # subdirectory, so we avoid copying across block devices.
        with tempfile.TemporaryDirectory(prefix="osbuild-unverified-file-", dir=self.cache) as tmpdir:
            tmpdir = pathlib.Path(tmpdir)
            return_code = self._download_items(tmpdir, items)
            self._verify_items(tmpdir, items)
        return return_code

    def _download_items(self, tmpdir: pathlib.Path, items: Dict):
        curl_config_path = tmpdir / "curl-config.txt"
        _gen_curl_download_config(items, curl_config_path)
        # TODO: add --parallel here with new enough curl
        curl_command = [
            "curl",
            "--silent",
            "--speed-limit", "1000",
            "--connect-timeout", "30",
            "--fail",
            "--location",
            "--config", os.fspath(curl_config_path),
        ]
        if _curl_has_parallel_downloads():
            curl_command.append("--parallel")
        curl = subprocess.run(
            curl_command, encoding="utf-8", cwd=tmpdir, check=False)
        return curl.returncode

    def _verify_items(self, tmpdir: pathlib.Path, items: Dict):
        for checksum, desc in items.items():
            downloaded_path = tmpdir / checksum
            if not downloaded_path.exists():
                continue
            if not verify_file(downloaded_path, checksum):
                raise RuntimeError(f"checksum mismatch: {checksum} {desc['url']}")

            # The checksum has been verified, move the file into place. in case we race
            # another download of the same file, we simply ignore the error as their
            # contents are guaranteed to be  the same.
            try:
                os.rename(f"{tmpdir}/{checksum}", f"{self.cache}/{checksum}")
            except FileExistsError:
                pass


def main():
    service = CurlSource.from_args(sys.argv[1:])
    service.main()


if __name__ == '__main__':
    main()
